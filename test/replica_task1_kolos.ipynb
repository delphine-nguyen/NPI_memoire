{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import csv\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "checkpoint = \"bert-base-uncased\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "labels = []\n",
    "\n",
    "with open(\"../data/fake_dataset.csv\") as csvfile:\n",
    "    \n",
    "    reader = csv.reader(csvfile, delimiter=\",\")\n",
    "    \n",
    "    temp_tokens = []\n",
    "    temp_labels = []\n",
    "    \n",
    "    next(reader) # Ignore première ligne (en-tête)\n",
    "    \n",
    "    for row in reader:\n",
    "        \n",
    "        if row == [\"#\", \"#\"]: # Nouvelle phrase\n",
    "            \n",
    "            # Ajout des listes tampon\n",
    "            tokens.append(temp_tokens)\n",
    "            labels.append(temp_labels)\n",
    "            \n",
    "            # On vide les listes tampon\n",
    "            temp_tokens = []\n",
    "            temp_labels = []\n",
    "        \n",
    "        else:\n",
    "            temp_tokens.append(row[0])\n",
    "            temp_labels.append(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape () instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[88], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m label_encoder \u001b[39m=\u001b[39m LabelEncoder()\n\u001b[0;32m      2\u001b[0m label_encoder\u001b[39m.\u001b[39mfit([\u001b[39m\"\u001b[39m\u001b[39mO\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mB-NPI\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mI-NPI\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m----> 4\u001b[0m label_ids \u001b[39m=\u001b[39m [[label_encoder\u001b[39m.\u001b[39mtransform(label) \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m sent_labels] \u001b[39mfor\u001b[39;00m sent_labels \u001b[39min\u001b[39;00m labels]\n",
      "Cell \u001b[1;32mIn[88], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m label_encoder \u001b[39m=\u001b[39m LabelEncoder()\n\u001b[0;32m      2\u001b[0m label_encoder\u001b[39m.\u001b[39mfit([\u001b[39m\"\u001b[39m\u001b[39mO\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mB-NPI\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mI-NPI\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m----> 4\u001b[0m label_ids \u001b[39m=\u001b[39m [[label_encoder\u001b[39m.\u001b[39mtransform(label) \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m sent_labels] \u001b[39mfor\u001b[39;00m sent_labels \u001b[39min\u001b[39;00m labels]\n",
      "Cell \u001b[1;32mIn[88], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m label_encoder \u001b[39m=\u001b[39m LabelEncoder()\n\u001b[0;32m      2\u001b[0m label_encoder\u001b[39m.\u001b[39mfit([\u001b[39m\"\u001b[39m\u001b[39mO\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mB-NPI\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mI-NPI\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m----> 4\u001b[0m label_ids \u001b[39m=\u001b[39m [[label_encoder\u001b[39m.\u001b[39;49mtransform(label) \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m sent_labels] \u001b[39mfor\u001b[39;00m sent_labels \u001b[39min\u001b[39;00m labels]\n",
      "File \u001b[1;32mc:\\Users\\aengp\\Desktop\\memoire\\.venvMemoire\\lib\\site-packages\\sklearn\\utils\\_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 142\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    144\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    145\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    147\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    148\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\aengp\\Desktop\\memoire\\.venvMemoire\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:134\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Transform labels to normalized encoding.\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \n\u001b[0;32m    123\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39m    Labels as normalized encodings.\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    133\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 134\u001b[0m y \u001b[39m=\u001b[39m column_or_1d(y, dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclasses_\u001b[39m.\u001b[39;49mdtype, warn\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    135\u001b[0m \u001b[39m# transform of empty array is empty array\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[39mif\u001b[39;00m _num_samples(y) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\aengp\\Desktop\\memoire\\.venvMemoire\\lib\\site-packages\\sklearn\\utils\\validation.py:1202\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, dtype, warn)\u001b[0m\n\u001b[0;32m   1193\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1194\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mA column-vector y was passed when a 1d array was\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1195\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m expected. Please change the shape of y to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1198\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m   1199\u001b[0m         )\n\u001b[0;32m   1200\u001b[0m     \u001b[39mreturn\u001b[39;00m _asarray_with_order(xp\u001b[39m.\u001b[39mreshape(y, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC\u001b[39m\u001b[39m\"\u001b[39m, xp\u001b[39m=\u001b[39mxp)\n\u001b[1;32m-> 1202\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1203\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39my should be a 1d array, got an array of shape \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(shape)\n\u001b[0;32m   1204\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: y should be a 1d array, got an array of shape () instead."
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit([\"O\", \"B-NPI\", \"I-NPI\"])\n",
    "\n",
    "label_ids = [[label_encoder.transform(label) for label in sent_labels] for sent_labels in labels]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise en forme des données dans le bon format pour BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39;49mtensor(labels)\n",
      "\u001b[1;31mValueError\u001b[0m: too many dimensions 'str'"
     ]
    }
   ],
   "source": [
    "torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 19\u001b[0m\n\u001b[0;32m     14\u001b[0m padded_tokens \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mrnn\u001b[39m.\u001b[39mpad_sequence(processed_tokens, \n\u001b[0;32m     15\u001b[0m                                                 batch_first\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     16\u001b[0m                                                 padding_value\u001b[39m=\u001b[39mtokenizer\u001b[39m.\u001b[39mpad_token_id)\n\u001b[0;32m     18\u001b[0m \u001b[39m# Application du padding (ajout de tokens spéciaux pour que toutes les phrases aient la même longueur)\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m padded_labels \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mrnn\u001b[39m.\u001b[39mpad_sequence(torch\u001b[39m.\u001b[39;49mtensor(labels), \n\u001b[0;32m     20\u001b[0m                                                 batch_first\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     21\u001b[0m                                                 padding_value\u001b[39m=\u001b[39mtokenizer\u001b[39m.\u001b[39mpad_token_id)\n\u001b[0;32m     23\u001b[0m \u001b[39m# Création de l'attention mask\u001b[39;00m\n\u001b[0;32m     24\u001b[0m attention_mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros_like(padded_tokens) \u001b[39m# Création d'un tensor rempli de 0 avec la même shape que padded_tokens\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: too many dimensions 'str'"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "processed_tokens = []\n",
    "\n",
    "for sentence in tokens:\n",
    "    \n",
    "    # Conversion des tokens en IDs\n",
    "    # Et ajout des special tokens [CLS] et [SEP]\n",
    "    input_ids = [tokenizer.cls_token_id] + [tokenizer.convert_tokens_to_ids(token) for token in sentence] + [tokenizer.sep_token_id]\n",
    "    \n",
    "    processed_tokens.append(torch.tensor(input_ids))\n",
    "    \n",
    "# Application du padding (ajout de tokens spéciaux pour que toutes les phrases aient la même longueur)\n",
    "padded_tokens = torch.nn.utils.rnn.pad_sequence(processed_tokens, \n",
    "                                                batch_first=True,\n",
    "                                                padding_value=tokenizer.pad_token_id)\n",
    "\n",
    "# Application du padding (ajout de tokens spéciaux pour que toutes les phrases aient la même longueur)\n",
    "padded_labels = torch.nn.utils.rnn.pad_sequence(torch.tensor(labels), \n",
    "                                                batch_first=True,\n",
    "                                                padding_value=tokenizer.pad_token_id)\n",
    "\n",
    "# Création de l'attention mask\n",
    "attention_mask = torch.zeros_like(padded_tokens) # Création d'un tensor rempli de 0 avec la même shape que padded_tokens\n",
    "attention_mask[padded_tokens != tokenizer.pad_token_id] = 1 # Si le token est différent du token de padding, on met 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'padded_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m padded_labels\n",
      "\u001b[1;31mNameError\u001b[0m: name 'padded_labels' is not defined"
     ]
    }
   ],
   "source": [
    "padded_labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, \n",
    "                                                           num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [8] at entry 0 and [12] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m     13\u001b[0m \u001b[39m# Loop through the batches\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m dataloader:\n\u001b[0;32m     15\u001b[0m \n\u001b[0;32m     16\u001b[0m     \u001b[39m# Extract the input IDs, token type IDs, and attention masks for this batch\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     input_ids \u001b[39m=\u001b[39m batch[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     18\u001b[0m     token_type_ids \u001b[39m=\u001b[39m batch[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\aengp\\Desktop\\memoire\\.venvMemoire\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\aengp\\Desktop\\memoire\\.venvMemoire\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\aengp\\Desktop\\memoire\\.venvMemoire\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:61\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 61\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[1;32mc:\\Users\\aengp\\Desktop\\memoire\\.venvMemoire\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    205\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39;49mdefault_collate_fn_map)\n",
      "File \u001b[1;32mc:\\Users\\aengp\\Desktop\\memoire\\.venvMemoire\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:143\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    140\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m--> 143\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\aengp\\Desktop\\memoire\\.venvMemoire\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:143\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    140\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m--> 143\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\aengp\\Desktop\\memoire\\.venvMemoire\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:120\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39mif\u001b[39;00m collate_fn_map \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m     \u001b[39mif\u001b[39;00m elem_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 120\u001b[0m         \u001b[39mreturn\u001b[39;00m collate_fn_map[elem_type](batch, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map)\n\u001b[0;32m    122\u001b[0m     \u001b[39mfor\u001b[39;00m collate_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    123\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\Users\\aengp\\Desktop\\memoire\\.venvMemoire\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:163\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    161\u001b[0m     storage \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mstorage()\u001b[39m.\u001b[39m_new_shared(numel, device\u001b[39m=\u001b[39melem\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m    162\u001b[0m     out \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mnew(storage)\u001b[39m.\u001b[39mresize_(\u001b[39mlen\u001b[39m(batch), \u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(elem\u001b[39m.\u001b[39msize()))\n\u001b[1;32m--> 163\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(batch, \u001b[39m0\u001b[39;49m, out\u001b[39m=\u001b[39;49mout)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [8] at entry 0 and [12] at entry 1"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "\n",
    "data = list(zip(processed_tokens, labels, attention_mask))\n",
    "dataloader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Set up the loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Put the model into training mode\n",
    "model.train()\n",
    "\n",
    "\n",
    "# Loop through the batches\n",
    "for batch in dataloader:\n",
    "\n",
    "    # Extract the input IDs, token type IDs, and attention masks for this batch\n",
    "    input_ids = batch[0]['input_ids']\n",
    "    token_type_ids = batch[0]['token_type_ids']\n",
    "    attention_mask = batch[2]\n",
    "    \n",
    "    # Pass the inputs through the BERT model to obtain hidden representations for each token\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n",
    "        hidden_states = outputs[0]\n",
    "    \n",
    "    # Flatten the hidden states tensor and extract the hidden states for non-padding tokens\n",
    "    flattened_hidden_states = hidden_states.view(-1, hidden_states.shape[-1])\n",
    "    non_padding_mask = attention_mask.view(-1) == 1\n",
    "    token_hidden_states = flattened_hidden_states[non_padding_mask]\n",
    "    \n",
    "    # Classify the tokens into one of the three classes\n",
    "    logits = model.classifier(token_hidden_states)\n",
    "    probabilities = torch.softmax(logits, dim=-1)\n",
    "    predicted_labels = torch.argmax(probabilities, dim=-1)\n",
    "    \n",
    "    # Compute the loss\n",
    "    true_labels = batch[1]\n",
    "    non_padding_labels = true_labels[non_padding_mask]\n",
    "    loss = loss_fn(logits, non_padding_labels)\n",
    "    \n",
    "    # Print the loss\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmasker = pipeline(\"fill-mask\", model = \"bert-base-uncased\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvMemoire",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "39002e7d175a3b46ac49ee1070e80e806334a8911058f9756deae5d8e0ecee95"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
